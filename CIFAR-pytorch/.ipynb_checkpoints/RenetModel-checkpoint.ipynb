{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80df4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 1: Define required functions for Data processing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor\n",
    "import os\n",
    "import argparse\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "\n",
    "def balance_val_split(dataset, train_size=12500):\n",
    "\n",
    "    try:\n",
    "        targets = np.array(dataset.targets)\n",
    "    except:\n",
    "        targets = []  # create an empty list to store the targets\n",
    "        for data in dataset.datasets:\n",
    "            targets += data.targets  # concatenate the targets from each dataset into the list\n",
    "        targets = np.array(targets)\n",
    "    #targets = np.array(dataset.datasets.targets)\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(targets.shape[0]),\n",
    "        train_size=train_size,\n",
    "        stratify=targets\n",
    "    )\n",
    "    train_dataset = Subset(dataset, indices=train_indices)\n",
    "    # Get the data from the subset dataset\n",
    "    subset_data = [train_dataset[idx][0] for idx in range(len(train_dataset))]\n",
    "    subset_labels = [train_dataset[idx][1] for idx in range(len(train_dataset))]\n",
    "    # Create a dataset from the list of data and targets\n",
    "    train_dataset = MyDataset(subset_data, subset_labels)\n",
    "    \n",
    "    \n",
    "    val_dataset = Subset(dataset, indices=val_indices)\n",
    "    # Get the data from the subset dataset\n",
    "    subset_data = [val_dataset[idx][0] for idx in range(len(val_dataset))]\n",
    "    subset_labels = [val_dataset[idx][1] for idx in range(len(val_dataset))]\n",
    "    # Create a dataset from the list of data and targets\n",
    "    val_dataset = MyDataset(subset_data, subset_labels)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def count_label_frequency(target_train_dataset):\n",
    "\tfrom collections import Counter\n",
    "\ttarget_labels = []  # create an empty list to store the labels\n",
    "\n",
    "\tfor i in range(len(target_train_dataset)):\n",
    "\t\t\t_, label = target_train_dataset[i]  # extract the label for the i-th example in the subset\n",
    "\t\t\ttarget_labels.append(label)  # append the label to the 'subset_labels' list\n",
    "\n",
    "\n",
    "\treturn Counter(target_labels)\n",
    " \n",
    "\n",
    "\n",
    "def custom_transform(image: Tensor) -> Tensor:\n",
    "    import random\n",
    "    # randomly flip horizontally or vertically with 25% chance\n",
    "    if random.random() < 0.25:\n",
    "        image = RandomHorizontalFlip(p=1)(image)\n",
    "    elif random.random() < 0.5:\n",
    "        image = RandomVerticalFlip(p=1)(image)\n",
    "    \n",
    "    # randomly shift the image by 2 pixels to the left or right with 25% chance\n",
    "    if random.random() < 0.25:\n",
    "        image = RandomCrop((image.shape[-2], image.shape[-1] - 2), pad_if_needed=False)(image)\n",
    "    elif random.random() < 0.5:\n",
    "        image = RandomCrop((image.shape[-2], image.shape[-1] + 2), pad_if_needed=False)(image)\n",
    "        \n",
    "    # randomly shift the image by 2 pixels to the top or bottom with 25% chance\n",
    "    if random.random() < 0.25:\n",
    "        image = RandomCrop((image.shape[-2] - 2, image.shape[-1]), pad_if_needed=False)(image)\n",
    "    elif random.random() < 0.5:\n",
    "        image = RandomCrop((image.shape[-2] + 2, image.shape[-1]), pad_if_needed=False)(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 2: Define required functions for Data Training\n",
    "\n",
    "# Training\n",
    "def train(trainloader, epoch, batch_size=128, logfile = \"train.summary\"):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        #inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        if inputs.shape[0] != batch_size:\n",
    "          print(inputs.shape)\n",
    "          continue\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx % 30 == 0:\n",
    "                print(batch_idx, len(trainloader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print(len(trainloader), 'Epoch: %d | Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                     % (epoch, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    f = open(logfile, \"a\")\n",
    "    f.write('Epoch: %d | Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)\\n'\n",
    "                     % (epoch, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    f.close()\n",
    "\n",
    "def test(testloader, epoch, batch_size=128, logfile = \"train.summary\", save_modelpath = './DLA'):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            #inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx % 30 == 0:\n",
    "                print(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print(len(testloader), 'Epoch: %d | Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                         % (epoch, test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    f = open(logfile, \"a\")\n",
    "    f.write('Epoch: %d | Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)\\n'\n",
    "                         % (epoch, test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    f.close()\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(save_modelpath):\n",
    "            os.mkdir(save_modelpath)\n",
    "        torch.save(state, save_modelpath+'/ckpt.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "def draw_training_summary(filepath = 'target_train_DCA-BiLSTM.summary'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        results_summary = f.read()\n",
    "\n",
    "    train_epoch = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_epoch = []\n",
    "    test_loss=[]\n",
    "    test_acc=[]\n",
    "    for line in results_summary.split(\"\\n\"):\n",
    "        try:\n",
    "            r_epoch = line.split('|')[0].strip().split(' ')[1]\n",
    "            r_loss = line.split('|')[1].strip().split(' ')[2].replace('%','')\n",
    "            r_acc = line.split('|')[2].strip().split(' ')[2].replace('%','')\n",
    "            if 'Train' in line:\n",
    "                train_epoch.append(int(r_epoch))\n",
    "                train_loss.append(float(r_loss))\n",
    "                train_acc.append(float(r_acc))\n",
    "            if 'Test' in line:\n",
    "                test_epoch.append(int(r_epoch))\n",
    "                test_loss.append(float(r_loss))\n",
    "                test_acc.append(float(r_acc))\n",
    "        except:\n",
    "            print(line)\n",
    "\n",
    "    # Create a new figure and plot the data\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.plot(test_acc, label='Test')\n",
    "    plt.axhline(y=np.max(test_acc), color='r', linestyle='--')\n",
    "    # Add text for the horizontal line\n",
    "    plt.text(test_epoch[-10], np.max(test_acc)*1.05, np.max(test_acc), color='r', fontsize=10)\n",
    "    # Customize the plot\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_loss, label='Train')\n",
    "    plt.plot(test_loss, label='Test')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c20085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 3: Prepare Cifar10 dataset for target and shadow model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "def create_cifar_dataset_torch(batch_size=128, target_train_size = 15000, target_test_size= 15000, shadow_train_size = 15000, shadow_test_size= 15000):\n",
    "\n",
    "  # Data\n",
    "  print('==> Preparing data..')\n",
    "\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "  \n",
    "  cifar_trainset = torchvision.datasets.CIFAR10(\n",
    "      root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "  cifar_testset = torchvision.datasets.CIFAR10(\n",
    "      root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "  cifar_dataset = torch.utils.data.ConcatDataset([cifar_trainset, cifar_testset])\n",
    "\n",
    "\n",
    "  #target_train_size = int(0.25 * len(cifar_dataset)) # 15000\n",
    "  remain_size = len(cifar_dataset) - target_train_size\n",
    "  target_train_dataset, remain_dataset = torch.utils.data.random_split(cifar_dataset, [target_train_size, remain_size])\n",
    "\n",
    "  #target_test_size = int(0.25 * len(cifar_dataset)) # 15000\n",
    "  remain_size = len(remain_dataset) - target_test_size\n",
    "  target_test_dataset, remain_dataset = torch.utils.data.random_split(remain_dataset, [target_test_size, remain_size])\n",
    "\n",
    "  #target_test_dataset, remain_dataset = balance_val_split(remain_dataset, train_size=target_test_size)\n",
    "\n",
    "\n",
    "  #shadow_train_size = int(0.25 * len(cifar_dataset)) # 15000\n",
    "  remain_size = len(remain_dataset) - shadow_train_size\n",
    "  shadow_train_dataset, shadow_test_dataset = torch.utils.data.random_split(remain_dataset, [shadow_train_size, remain_size])\n",
    "  #shadow_train_dataset, shadow_test_dataset = balance_val_split(remain_dataset, train_size=shadow_train_size)\n",
    "\n",
    "  print(\"Setting target_train_dataset size to \",len(target_train_dataset), count_label_frequency(target_train_dataset))\n",
    "  print(\"Setting target_test_dataset size to \",len(target_test_dataset), count_label_frequency(target_test_dataset))\n",
    "  print(\"Setting shadow_train_dataset size to \",len(shadow_train_dataset), count_label_frequency(shadow_train_dataset))\n",
    "  print(\"Setting shadow_test_dataset size to \",len(shadow_test_dataset), count_label_frequency(shadow_test_dataset))\n",
    "  #print(\"Setting testset size to \",len(testset))\n",
    "\n",
    "\n",
    "\n",
    "  '''\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "  '''\n",
    "\n",
    "\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      custom_transform,\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  # apply the data augmentation transformations to the subset\n",
    "  target_train_dataset.dataset.transform = transform_train\n",
    "  # Load the transformed subset using a DataLoader\n",
    "  target_trainloader = DataLoader(target_train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "\n",
    "  target_test_dataset.dataset.transform = transform_test\n",
    "  # Load the transformed subset using a DataLoader\n",
    "  target_testloader = DataLoader(target_test_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "\n",
    "  # apply the data augmentation transformations to the subset\n",
    "  shadow_train_dataset.dataset.transform = transform_train\n",
    "  # Load the transformed subset using a DataLoader\n",
    "  shadow_trainloader = DataLoader(shadow_train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "\n",
    "  shadow_test_dataset.dataset.transform = transform_test\n",
    "  # Load the transformed subset using a DataLoader\n",
    "  shadow_testloader = DataLoader(shadow_test_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "  return target_trainloader, target_testloader, shadow_trainloader, shadow_testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66193a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 4.1: Define required functions for ReNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#on hopper: pip install --upgrade torch==2.0.0+cu118 torchvision==0.15.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n",
    "\n",
    "# renet with one layer\n",
    "class ReNet(nn.Module):\n",
    "\tdef __init__(self, receptive_filter_size, hidden_size, batch_size, image_patches_height, image_patches_width):\n",
    "\n",
    "\t\tsuper(ReNet, self).__init__()\n",
    "\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.receptive_filter_size = receptive_filter_size\n",
    "\t\tself.input_size1 = receptive_filter_size * receptive_filter_size * 3\n",
    "\t\tself.input_size2 = hidden_size * 2\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\n",
    "\t\t# vertical rnns\n",
    "\t\tself.rnn1 = nn.LSTM(self.input_size1, self.hidden_size, dropout = 0.2)\n",
    "\t\tself.rnn2 = nn.LSTM(self.input_size1, self.hidden_size, dropout = 0.2)\n",
    "\n",
    "\t\t# horizontal rnns\n",
    "\t\tself.rnn3 = nn.LSTM(self.input_size2, self.hidden_size, dropout = 0.2)\n",
    "\t\tself.rnn4 = nn.LSTM(self.input_size2, self.hidden_size, dropout = 0.2)\n",
    "\n",
    "\t\tself.initHidden()\n",
    "\n",
    "\t\tfeature_map_dim = int(image_patches_height*image_patches_height*hidden_size*2)\n",
    "\t\t#self.conv1 = nn.Conv2d(hidden_size*2, 2, 3,padding=1)#[1,640,8,8]->[1,1,8,8]\n",
    "\t\t#self.UpsamplingBilinear2d=nn.UpsamplingBilinear2d(size=(32,32), scale_factor=None)\n",
    "\t\tself.dense = nn.Linear(feature_map_dim, 1024) #4096\n",
    "\t\tself.fc = nn.Linear(1024, 10)\n",
    "\n",
    "\t\tself.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "\tdef initHidden(self):\n",
    "\t\tself.hidden = (Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()), Variable(torch.zeros(1, self.batch_size, self.hidden_size)).cuda())\n",
    "\n",
    "\n",
    "\tdef get_image_patches(self, X, receptive_filter_size):\n",
    "\t\t\"\"\"\n",
    "\t\tcreates image patches based on the dimension of a receptive filter\n",
    "\t\t\"\"\"\n",
    "\t\timage_patches = []\n",
    "\n",
    "\t\t_, X_channel, X_height, X_width= X.size()\n",
    "\n",
    "\n",
    "\t\tfor i in range(0, X_height, receptive_filter_size):\n",
    "\t\t\tfor j in range(0, X_width, receptive_filter_size):\n",
    "\t\t\t\tX_patch = X[:, :, i: i + receptive_filter_size, j : j + receptive_filter_size]\n",
    "\t\t\t\timage_patches.append(X_patch)\n",
    "\n",
    "\t\timage_patches_height = (X_height // receptive_filter_size)\n",
    "\t\timage_patches_width = (X_width // receptive_filter_size)\n",
    "\n",
    "\n",
    "\t\timage_patches = torch.stack(image_patches)\n",
    "\t\timage_patches = image_patches.permute(1, 0, 2, 3, 4)\n",
    "\t\t#print(\"image_patches: \",image_patches.shape)\n",
    "\n",
    "\t\timage_patches = image_patches.contiguous().view(-1, image_patches_height, image_patches_height, receptive_filter_size * receptive_filter_size * X_channel)\n",
    "\n",
    "\t\treturn image_patches\n",
    "\n",
    "\n",
    "\n",
    "\tdef get_vertical_rnn_inputs(self, image_patches, forward):\n",
    "\t\t\"\"\"\n",
    "\t\tcreates vertical rnn inputs in dimensions \n",
    "\t\t(num_patches, batch_size, rnn_input_feature_dim)\n",
    "\t\tnum_patches: image_patches_height * image_patches_width\n",
    "\t\t\"\"\"\n",
    "\t\tvertical_rnn_inputs = []\n",
    "\t\t_, image_patches_height, image_patches_width, feature_dim = image_patches.size()\n",
    "\n",
    "\t\tif forward:\n",
    "\t\t\tfor i in range(image_patches_height):\n",
    "\t\t\t\tfor j in range(image_patches_width):\n",
    "\t\t\t\t\tvertical_rnn_inputs.append(image_patches[:, j, i, :])\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tfor i in range(image_patches_height-1, -1, -1):\n",
    "\t\t\t\tfor j in range(image_patches_width-1, -1, -1):\n",
    "\t\t\t\t\tvertical_rnn_inputs.append(image_patches[:, j, i, :])\n",
    "\n",
    "\t\tvertical_rnn_inputs = torch.stack(vertical_rnn_inputs)\n",
    "\n",
    "\n",
    "\t\treturn vertical_rnn_inputs\n",
    "\n",
    "\n",
    "\n",
    "\tdef get_horizontal_rnn_inputs(self, vertical_feature_map, image_patches_height, image_patches_width, forward):\n",
    "\t\t\"\"\"\n",
    "\t\tcreates vertical rnn inputs in dimensions \n",
    "\t\t(num_patches, batch_size, rnn_input_feature_dim)\n",
    "\t\tnum_patches: image_patches_height * image_patches_width\n",
    "\t\t\"\"\"\n",
    "\t\thorizontal_rnn_inputs = []\n",
    "\n",
    "\t\tif forward:\n",
    "\t\t\tfor i in range(image_patches_height):\n",
    "\t\t\t\tfor j in range(image_patches_width):\n",
    "\t\t\t\t\thorizontal_rnn_inputs.append(vertical_feature_map[:, i, j, :])\n",
    "\t\telse:\n",
    "\t\t\tfor i in range(image_patches_height-1, -1, -1):\n",
    "\t\t\t\tfor j in range(image_patches_width -1, -1, -1):\n",
    "\t\t\t\t\thorizontal_rnn_inputs.append(vertical_feature_map[:, i, j, :])\n",
    "\t\t\n",
    "\t\thorizontal_rnn_inputs = torch.stack(horizontal_rnn_inputs)\n",
    "\n",
    "\t\treturn horizontal_rnn_inputs\n",
    "\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\n",
    "\t\t\"\"\"ReNet \"\"\"\n",
    "\n",
    "\t\t# divide input input image to image patches\n",
    "\t\timage_patches = self.get_image_patches(X, self.receptive_filter_size)\n",
    "\t\t_, image_patches_height, image_patches_width, feature_dim = image_patches.size()\n",
    "\n",
    "\t\t# process vertical rnn inputs\n",
    "\t\tvertical_rnn_inputs_fw = self.get_vertical_rnn_inputs(image_patches, forward=True)\n",
    "\t\tvertical_rnn_inputs_rev = self.get_vertical_rnn_inputs(image_patches, forward=False)\n",
    "    \n",
    "\t\t#print(\"vertical_rnn_inputs_fw: \",vertical_rnn_inputs_fw.shape)\n",
    "\t\t#print(\"vertical_rnn_inputs_rev: \",vertical_rnn_inputs_rev.shape)\n",
    "\t\t# extract vertical hidden states\n",
    "\t\tvertical_forward_hidden, vertical_forward_cell = self.rnn1(vertical_rnn_inputs_fw, self.hidden)\n",
    "\t\tvertical_reverse_hidden, vertical_reverse_cell = self.rnn2(vertical_rnn_inputs_rev, self.hidden)\n",
    "\n",
    "\t\t# create vertical feature map\n",
    "\t\tvertical_feature_map = torch.cat((vertical_forward_hidden, vertical_reverse_hidden), 2)\n",
    "\t\tvertical_feature_map =  vertical_feature_map.permute(1, 0, 2)\n",
    "\n",
    "\t\t# reshape vertical feature map to (batch size, image_patches_height, image_patches_width, hidden_size * 2)\n",
    "\t\tvertical_feature_map = vertical_feature_map.contiguous().view(-1, image_patches_width, image_patches_height, self.hidden_size * 2)\n",
    "\t\tvertical_feature_map.permute(0, 2, 1, 3)\n",
    "\n",
    "\t\t# process horizontal rnn inputs\n",
    "\t\thorizontal_rnn_inputs_fw = self.get_horizontal_rnn_inputs(vertical_feature_map, image_patches_height, image_patches_width, forward=True)\n",
    "\t\thorizontal_rnn_inputs_rev = self.get_horizontal_rnn_inputs(vertical_feature_map, image_patches_height, image_patches_width, forward=False)\n",
    "\n",
    "\t\t#print(\"horizontal_rnn_inputs_fw1: \",horizontal_rnn_inputs_fw.shape)\n",
    "\t\t#print(\"horizontal_rnn_inputs_rev1: \",horizontal_rnn_inputs_rev.shape)\n",
    "\t\t# extract horizontal hidden states\n",
    "\t\thorizontal_forward_hidden, horizontal_forward_cell = self.rnn3(horizontal_rnn_inputs_fw, self.hidden)\n",
    "\t\thorizontal_reverse_hidden, horizontal_reverse_cell = self.rnn4(horizontal_rnn_inputs_rev, self.hidden)\n",
    "\n",
    "\t\t# create horiztonal feature map[64,1,320]\n",
    "\t\t#print(\"horizontal_forward_hidden2: \",horizontal_forward_hidden.shape)\n",
    "\t\t#print(\"horizontal_reverse_hidden2: \",horizontal_reverse_hidden.shape)\n",
    "\t\thorizontal_feature_map = torch.cat((horizontal_forward_hidden, horizontal_reverse_hidden), 2)\n",
    "\t\thorizontal_feature_map =  horizontal_feature_map.permute(1, 0, 2)\n",
    "\n",
    "\t\t# flatten[1,64,640]\n",
    "\t\toutput = horizontal_feature_map.contiguous().view(-1, image_patches_height , image_patches_width , self.hidden_size * 2)\n",
    "\t\toutput = output.view(output.size(0), -1)\n",
    "\t\t#output=output.permute(0,3,1,2)#[1,640,8,8]\n",
    "\t\t#conv1=self.conv1(output)\n",
    "\t\t#Upsampling=self.UpsamplingBilinear2d(conv1)\n",
    "\t\t# dense layer\n",
    "\t\toutput = F.relu(self.dense(output))\n",
    "\t\t \n",
    "\t\t# fully connected layer\n",
    "\t\tlogits = self.fc(output)\n",
    "\n",
    "\t\t# log softmax\n",
    "\t\t#logits = self.log_softmax(Upsampling)\n",
    "\n",
    "\t\treturn logits\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    s = '%s' % (asMinutes(s))\n",
    "    return s\n",
    "\n",
    "\n",
    "'''Some helper functions for PyTorch, including:\n",
    "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
    "    - msr_init: net parameter initialization.\n",
    "    - progress_bar: progress bar mimic xlua.progress.\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ee9394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model for ReNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omars\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training model from scratch..\n",
      "Total trained parameters:  45364234\n",
      "ReNet(\n",
      "  (rnn1): LSTM(48, 320, dropout=0.2)\n",
      "  (rnn2): LSTM(48, 320, dropout=0.2)\n",
      "  (rnn3): LSTM(640, 320, dropout=0.2)\n",
      "  (rnn4): LSTM(640, 320, dropout=0.2)\n",
      "  (dense): Linear(in_features=40960, out_features=1024, bias=True)\n",
      "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#@title (Run) Part 5.1.1: Select an architecture for Target model training\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "#@markdown Enter the folder of path to the pdb files:\n",
    "#@markdown * Option 1: ReNet\n",
    "#@markdown * Option 2: DLA\n",
    "#@markdown * Option 3: DLA-LSTM\n",
    "#@markdown * Option 4: DLA-BiLSTM\n",
    "\n",
    "\n",
    "method_name = 'ReNet'  #@param {type:\"string\"}\n",
    "save_model_folder = './Target-ReNet_models/'   #@param {type:\"string\"}\n",
    "batch_size = 128  #@param {type:\"integer\"}\n",
    "load_pretrain_weight = False   #@param {type:\"boolean\"}\n",
    "\n",
    "if method_name == 'ReNet':\n",
    "  # Model\n",
    "  print('==> Building model for ' + method_name)\n",
    "\n",
    "  receptive_filter_size = 4\n",
    "  hidden_size = 320\n",
    "  image_size_w = 32\n",
    "  image_size_h = 32\n",
    "  \n",
    "\n",
    "  net = ReNet(receptive_filter_size, hidden_size, batch_size, image_size_w/receptive_filter_size, image_size_h/receptive_filter_size)\n",
    "  net.cuda()\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  \n",
    "  if load_pretrain_weight:\n",
    "    try:\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        checkpoint = torch.load(save_model_folder+'/ckpt.pth')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        best_acc = checkpoint['acc']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "    except:\n",
    "        print('!!! Error: no checkpoint directory found!')\n",
    "  else:\n",
    "    print('==> Training model from scratch..')\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
    "                        momentum=0.9, weight_decay=5e-4)\n",
    "  #optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "  pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "  print(\"Total trained parameters: \",pytorch_total_params)\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ff2546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Setting target_train_dataset size to  15000 Counter({9: 1544, 4: 1542, 1: 1518, 5: 1511, 7: 1503, 3: 1502, 6: 1482, 0: 1475, 8: 1472, 2: 1451})\n",
      "Setting target_test_dataset size to  15000 Counter({5: 1550, 2: 1533, 0: 1519, 9: 1518, 1: 1500, 7: 1490, 8: 1489, 3: 1479, 4: 1478, 6: 1444})\n",
      "Setting shadow_train_dataset size to  15000 Counter({0: 1584, 6: 1544, 8: 1525, 4: 1516, 3: 1505, 7: 1499, 2: 1474, 9: 1467, 5: 1451, 1: 1435})\n",
      "Setting shadow_test_dataset size to  15000 Counter({1: 1547, 2: 1542, 6: 1530, 8: 1514, 3: 1514, 7: 1508, 5: 1488, 9: 1471, 4: 1464, 0: 1422})\n"
     ]
    }
   ],
   "source": [
    "#@title (Run) Part 5.1.2: Setup Target and Shadow datasets for ReNet Training\n",
    "\n",
    "target_train_size = 15000 #@param {type:\"integer\"}\n",
    "target_test_size= 15000 #@param {type:\"integer\"}\n",
    "shadow_train_size = 15000  #@param {type:\"integer\"} \n",
    "shadow_test_size= 15000 #@param {type:\"integer\"}\n",
    "\n",
    "# create dataset for renet \n",
    "print('==> Preparing dataset..')\n",
    "target_trainloader, target_testloader, shadow_trainloader, shadow_testloader = create_cifar_dataset_torch(batch_size=batch_size, target_train_size = target_train_size, target_test_size= target_test_size, shadow_train_size = shadow_train_size, shadow_test_size= shadow_test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 5.1.3: Start Target model training\n",
    "\n",
    "max_epoch = 50  #@param {type:\"integer\"}\n",
    "train_result_summary = 'target_train_ReNet.summary'   #@param {type:\"string\"}\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "if not load_pretrain_weight:\n",
    "    f = open(train_result_summary, \"w\")\n",
    "    f.write('')\n",
    "    f.close()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+max_epoch):\n",
    "    train(target_trainloader, epoch, batch_size=batch_size, logfile = train_result_summary)\n",
    "    test(target_testloader, epoch, batch_size=batch_size, logfile = train_result_summary, save_modelpath = save_model_folder)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efceab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_training_summary(filepath = 'target_train_ReNet.summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 5.1.1: Select an architecture for Target model training\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "#@markdown Enter the folder of path to the pdb files:\n",
    "#@markdown * Option 1: ReNet\n",
    "#@markdown * Option 2: DLA\n",
    "#@markdown * Option 3: DLA-LSTM\n",
    "#@markdown * Option 4: DLA-BiLSTM\n",
    "\n",
    "\n",
    "method_name = 'ReNet'  #@param {type:\"string\"}\n",
    "save_model_folder = './Shadow-ReNet_models/'   #@param {type:\"string\"}\n",
    "batch_size = 128  #@param {type:\"integer\"}\n",
    "load_pretrain_weight = False   #@param {type:\"boolean\"}\n",
    "\n",
    "if method_name == 'ReNet':\n",
    "  # Model\n",
    "  print('==> Building model for ' + method_name)\n",
    "\n",
    "  receptive_filter_size = 4\n",
    "  hidden_size = 320\n",
    "  image_size_w = 32\n",
    "  image_size_h = 32\n",
    "  \n",
    "\n",
    "  net = ReNet(receptive_filter_size, hidden_size, batch_size, image_size_w/receptive_filter_size, image_size_h/receptive_filter_size)\n",
    "  net.cuda()\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  \n",
    "  if load_pretrain_weight:\n",
    "    try:\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        checkpoint = torch.load(save_model_folder+'/ckpt.pth')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        best_acc = checkpoint['acc']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "    except:\n",
    "        print('!!! Error: no checkpoint directory found!')\n",
    "  else:\n",
    "    print('==> Training model from scratch..')\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
    "                        momentum=0.9, weight_decay=5e-4)\n",
    "  #optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "  pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "  print(\"Total trained parameters: \",pytorch_total_params)\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd083a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Run) Part 5.1.3: Start Target model training\n",
    "\n",
    "max_epoch = 50  #@param {type:\"integer\"}\n",
    "train_result_summary = 'shadow_train_ReNet.summary'   #@param {type:\"string\"}\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "if not load_pretrain_weight:\n",
    "    f = open(train_result_summary, \"w\")\n",
    "    f.write('')\n",
    "    f.close()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+max_epoch):\n",
    "    train(shadow_trainloader, epoch, batch_size=batch_size, logfile = train_result_summary)\n",
    "    test(shadow_testloader, epoch, batch_size=batch_size, logfile = train_result_summary, save_modelpath = save_model_folder)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e761da",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_training_summary(filepath = 'shadow_train_ReNet.summary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
